# Here you can comment bench suite using markdown"
"19w51 SUPINT-1615 Check Readiness instance": "**#nco-47 vs #1950**


Instances running on Java 8 with `perf` template (no thumbnail generation, fulltext index on database disable)


**Import** Slower because of elastic


  - Waiting on indexing, all nodes CPU ~12%


**CSV Export** Similar


**Bulk Update on all documents** Slower because of elastic


  - 200% CPU on the node processing the Bulk command with 4 threads waiting on MongoDB, the load is not distributed because Kafka is not used.

  - After update waiting on asynchronous indexing (~12% on all nodes)


**Create/Update** Slower because of elastic


  - 350% CPU on front nodes, 60% CPU on worker node

  - Load on MongoDb and Redis

  - Wait on asynchronous indexing


**Search** Slower because of elastic


  - 100% CPU on front nodes


**Read** Similar


**Reindex** Slower because of elastic


   - 15% CPU on all nodes.


Elastic configuration:


  - index.translog.durability: async

  - number_of_replicas: 2

  - number_of_shards: 5

  - 344919 docs 1.3GB primary (3.9GB total)

  - 806627 audit entries 157.7MB primary (526.4MB total)


"

"19w41 NXBT-3006 Elastic 6.8 vs 6.4": "No visible difference between Elasticsearch 6.4.2/Java 8 and Elasticsearch 6.8.3/Java 11"


"Nuxeo LTS 2019": "By default Java 8 is used as runtime unless the classifier refers to Java 11.
Java 11 introduces a performance regression in the authentication layer [NXP-27917](https://jira.nuxeo.com/browse/NXP-27917).
This has been fixed only on the master branch (11.1-SNAPSHOT) therefore it is recommended to use Java 8 to run Nuxeo LTS 2019.


**Import** A bit lower than previous LTS


  - The refactoring of the fulltext extraction update has been done in [NXP-25716](https://jira.nuxeo.com/browse/NXP-25716)
    in Nuxeo 10.3 this improves performance but some new regression has been introduced, this will be analyzed on master branch.

  - As usual, the nuxeo-importer is run on a single node so the synchronous part
    do not benefit of having multiple Nuxeo node.  The limitation is
    mostly `Nuxeo CPU` at the beginning (especially for SQL backend)
    then `Nuxeo IO on S3`, then `SQL Backend IO` and `Backend CPU`.


**Create** Scales up limited by Gatling concurrency


  - Faster than previous LTS because of better latency (19ms vs 29ms on MongoDB) due to
    a fix in [NXP-25065](https://jira.nuxeo.com/browse/NXP-25065)

  - The throughput is limited by the response time for PostgreSQL (around 30ms) and
    the Gatling concurrency used (32 threads) which limit the possible
    load to 1000 req/s.


**Read** Scales up to 3500 req/s


  - This does not scale lineary with 4 nodes because of the injection concurrency (Gatling).


**Search** A bit slower than previous LTS


  - Elasticsearch upgrade from 5.6 to 6.3 shows comparable performance


**Update/CRUD** Scale up limited by Gatling concurrency, better than previous LTS


  - the latency around 30ms limits the possible throughput 1000 req/s with concurrency of 32.


**Reindex**


- A bit slower than in previous LTS.
"

"18w41 NXP-25632 bulk test": "Bulk service tests related to [NXP-25632](https://jira.nuxeo.com/browse/NXP-25632)


##### setProperties action on 1m documents


On build [#1688](./1688/index.html) the `setProperties` is tested on 1m documents with 8 threads we reach 1100 update/s:


![update throughput](https://benchmarks.nuxeo.com/build/1688/archive/reports/sim15bulkupdatedocuments/overview/nxDocumentsallnodes_1745_20181018.png 'Update')


The database and Nuxeos are ok for such a load::


![cpu idle](https://benchmarks.nuxeo.com/build/1688/archive/reports/sim15bulkupdatedocuments/overview/sysCPUIdle_1745_20181018.png 'Cpu Idle')


We can see different phases:


- The scrolling of 1m docs is fast ~15s (not visible but reported by command status)

- The action is running along with indexing and audit, it takes 14 minutes for the command to be completed ~1100 docs/s or ~130 doc/s/thread.

- After this the async task are running, the indexing is busy for 16 more minutes

- the audit writer needs half an hour again to complete


The reason for this is that `setProperties` action creates a new version and generates 3 log entries per document,
this puts more pressure on asynchronous task than on the action itself:


- 2m docs to index (document + version) around 1100 doc/s, there are 12 indexing threads

- 3m of log entries to write around 770 doc/s but with a single thread and with very few resources.

##### multiple setProperties concurrently


The Multi Bulk Update simulation created 50793 bulk command on document set of one document with a concurrency of 32 threads.


No error and a completion within 0.5s (p95 is 395ms) that proves that Bulk Action can be used for small document set.


##### CSV Export of 1m documents


This creates a 74MB csv.gz file, or 330MB csv file of 1m lines sorted line in 147s.


The projection in CSV line is done concurrently in a distributed way, there are activity in both nuxeo1 and nuxeo2 nodes:


![cpu idle](https://benchmarks.nuxeo.com/build/1688/archive/reports/sim20csvexport/overview/sysCPUIdle_1742_20181018.png 'Cpu Idle')

"

"18w34 NXP-25603 Kafka": "Redis is disabled when using Kafka with MongoDB.


The total duration is longer with Kafka because there is a single AuditLogWriter computation for the cluster instead
of one writer per node when using Redis. This ensure a constant throughput.


Cache invalidation for repository and directory is based the PubSub service. When using the Kafka implementations
we don't notice overhead on theses tests all Write operation that generate invalidation are comparable with or without Redis.


The PubSub messages used for invalidation in DBS/MongoDB are much smaller than in VCS, first because they denote a document id instead of schema fields but also
because they is a custom serialization and in the case of VCS they are Java serialized. This impacts the volume of the Kafka topics.


The Re-indexation looks a bit slower (2800 vs 3000 doc/s), certainly due to the lower concurrency on tail processing with Kafka.
Redis distributes works to available worker threads while Kafka assign partitions of works to worker threads.


"
"Nuxeo 10.2": "
First, we have removed some randomness in the results due to some improper configuration:


- Since Nuxeo 9.3 and the switch to Elasticsearch 5.6, the
  elasticsearch translog configuration defaults to request for the
  audit and sequencer index. This has created lots of elasticsearch
  disk IO stress during massive write operation. Note that the
  repository index was set properly to async using the perf template
  since 9.3.  This 10.2 milestone benchmark is done with all
  elasticsearch index configured in translog async.


- Since Nuxeo 9.3 the audit writer is implemented using a Nuxeo stream
  and we were not waiting to flush the audit between simulations.
  This has created some randomness and has impacted elasticsearch
  performance on some simulations. This is now fixed


- On successive benchmark that reuses existing elasticsearch nodes the
  audit index was not always reset between benchmarks.


[NXP-23016](https://jira.nuxeo.com/browse/NXP-23016) has fixed a regression
responsible for increasing response time of all request by few
milliseconds. This fix enables to reach higher throughput.


**import** Limited by a single node doing the import


**Create** Scale, limited by the injection (the request response time
  + injection concurrency)


**Read** Scale, limited by the injection


**Search** Limited by elasticsearch CPU


**CRUD** Scale, limited by injection


**Reindex** Limited by elasticsearch CPU and disk IO

"

"18w33 NXP-25355 Audit block of sequence": "
These tests shows 2 ways to improve mass audit log:


- By requesting log entries by block (available in 10.3) this saves a
  round trip per log entry making audit is written much faster. The
  pgsql import is reduced from 907s to 304s.

- By changing the elasticsearch translog from `request` to `async` for
  audit and sequence indexes: It saves a fsync per audit log entries,
  this remove all the stress on disk IO and don't impact any other
  elasticsearch activity.


Combining both gives a x3.4 gain, the total import duration is 261s vs 907s.
"

"Nuxeo LTS 2017": "**Import** Better than previous LTS


- The nuxeo-importer is run on a single node so the synchronous part
  do not benefit of having multiple Nuxeo node.  The limitation is
  mostly `Nuxeo CPU` at the beginning (especially for SQL backend)
  then `Nuxeo IO on S3`, then `SQL Backend IO` and `Backend CPU`.


**Create** Scales up to 3 nodes then plateauing around 1000 req/s for MongoDB:


  - The throughput is limited by the response time (around 29ms) and
    the Gatling concurrency used (32 threads) which limit the possible
    load to 1100 req/s. This high latency regression was introduced in
    [9.1](https://jira.nuxeo.com/browse/NXP-23016) and is fixed since
    [9.10-HF09](https://jira.nuxeo.com/browse/NXP-25065).  This
    regression in the directory invalidation has impacted all REST
    requests by adding few millisecond of latency.


**Read** Scales up to 2800 req/s


  - Here also the high average response time prevent to scale above 3000 req/s,
    9.10-HF09 should be much better.


**Search** Faster search


  - Elasticsearch upgrade from 2.3 to 5.6 shows comparable performance
    with some trend in slower write and faster search. A possible
    reason for the slowness in write is because sequence and audit
    indexes are in translog request mode.


**Update/CRUD**


  - Like with the Create simulation the throughput is limited by the
    concurrency and response time.  Upgrading to HF09 should help.


**Reindex**


- A bit slower than in previous LTS.
"

"Nuxeo 9.3": "Performance regression of 9.2 on [MongoDB](https://jira.nuxeo.com/browse/NXP-22411) has been addressed.


The [audit writer has been refactored to use Nuxeo Stream](https://jira.nuxeo.com/browse/NXP-22109) this improves writes operations.


Elasticsearch upgrade from 2.3 to 5.6 shows comparable performance with some trend in slower write and faster search.


**Import** Is back to normal an even better than LTS 2016


**Create** Scales up to 3 nodes then plateauing around 1200 req/s for MongoDB:


  - The throughput is limited by the response time (around 25ms) and the Gatling concurrency used (32 threads) which limit the possible load to 1280 req/s.
    Furthermore the sync response time that limit the throughput is not bounded to Nuxeo CPU as in LTS 2016 so adding more than 3 nodes does not help.

  - The total time sync + async is improved comparing to LTS 2016 with 4 nodes from 98s to 72s (+25% faster).


**Read** Scales with number of Nuxeo nodes


**Search** ES 5.x is a bit faster.


**Update/CRUD** performance are much better than in 9.2 with the new audit logger.


  - Like with the Create simulation the throughput is limited by the concurrency and response time.

  - The async time is better than in LTS 2016


**Reindex** Slower than with Elasticsearch 2.x, ES CPU bound, can be related to a slowness of the default fulltext analyzer with the `html_strip` char filter.


"


"17w47 DBS Cache or not": "Disabling the DBS cache with `nuxeo.dbs.cache.enabled=false` has almost no impact on write operations performance at this throughput. Read operations are more impacted, the additional round trips with storage starts to be a limitation because the throughput is much higher.


The gain of disabling DBS cache in cluster mode is that Redis is not needed anymore to manage the DBS cache invalidation."

"17w45 Stream workmanager": "This test is done with a single node using the StreamWorkmanager [NXP-22107](https://jira.nuxeo.com/browse/NXP-22107) based on Chronicle Queues, the async processing is done at a better constant throughput, in the create simulation there are a lot of indexing task performed in async, the total duration sync + async moves from 161s (127s sync + 34s async) to 118s, a gain of 25%, this is visible in the indexing rate as well:

 ![Default WorkManager](https://benchmarks.nuxeo.com/build/1163/archive/reports/sim20createdocuments/overview/nxElasticsearchindex_1159_20171110.png 'Default WorkManager') ![Stream WorkManager](https://benchmarks.nuxeo.com/build/1164/archive/reports/sim20createdocuments/overview/nxElasticsearchindex_1252_20171110.png 'Stream WorkManager')

"

"17w45 Elasticsearch translog sync vs async": "By default Elasticsearch fsync its translog on every request, switching from sync to async we have only one fsync every 5s.
The result is not visible during the create document simulation because the saturation is on the Nuxeo side but the iowait decreased from 50% to ~1%.

 ![sync chart](https://benchmarks.nuxeo.com/build/1162/archive/reports/sim10massimport/overview/sysCPUIoWait_1852_20171107.png 'Sync') ![async chart](https://benchmarks.nuxeo.com/build/1161/archive/reports/sim10massimport/overview/sysCPUIoWait_1753_20171107.png 'Async')


"

"17w45 Elasticsearch Rest vs Transport client": "The difference between Rest and Transport clients is not visible, benchmarks are now done with the Rest client"

"17w29 NXP-22764 mongodb directory connection pool": "The MongoDB client used to perform requests on the database
was initialized each time a session was created. As the client already manages its [own internal connection pool](http://api.mongodb.com/java/3.3/com/mongodb/MongoClient.html),
[initializing it at the directory level](https://jira.nuxeo.com/browse/NXP-22764) enables to fix the performance regression.
"

"Nuxeo 9.2": "- When choosing a MongoDB backend [the directories is now also stored in MongoDB](https://jira.nuxeo.com/browse/NXP-22411) by default.
This first implementation of MongoDB directories has limited performance due to a [lack of connection pool](https://jira.nuxeo.com/browse/NXP-22634).
This limit drastically all the REST throughput on high load, also on high pressure [some background work fails](https://jira.nuxeo.com/browse/NXP-22780) which prevent to get some results, for instance Reindexing throughput is not available (marked as NA).
In the mean time if you need high performance on MongoDB with 9.2 we suggest you fallback to a SQL directory implementation.

- A performance [regression in the audit logger](https://jira.nuxeo.com/browse/NXP-22774) impacts all operations.
"
"17w24 NXP-22421 db constraints": "Evaluate performance impact of database constaints as explained in [NXP-22421](https://jira.nuxeo.com/browse/NXP-22421), adding 5 constraints:


- hierarchy_parentid_name_1_idx UNIQUE, btree (parentid, name) WHERE isproperty = false


- hierarchy_parentid_name_2_idx UNIQUE, btree (parentid, name) WHERE isproperty = true AND pos IS NULL


- hierarchy_parentid_name_3_idx UNIQUE, btree (parentid, name, pos) WHERE isproperty = true AND pos IS NOT NULL


- dc_subjects_id_pos_id UNIQUE, btree (id, pos)


- dc_contributors_id_pos_idx UNIQUE, btree (id, pos)


No visible performance impact on the default simulations, it might require more volume/concurrency.
"

"Nuxeo 9.1": "- A new **MarkLogic** backend has been added to the benchmark matrix.


- Since LTS 2016 the **import** has been tuned on DBS (MongoDB and MarkLogic) to [remove contentions](https://jira.nuxeo.com/browse/NXP-21712),
  [reduce the number of queries](https://jira.nuxeo.com/browse/NXP-20595) and [make cache more efficient](https://jira.nuxeo.com/browse/NXP-21678),
  improving the import throughput by **20%**.


- The **Elasticsearch reindexing** has been improved by [limiting the size of bulk command](https://jira.nuxeo.com/browse/NXP-21227) and by [reducing the JSON representation](https://jira.nuxeo.com/browse/NXP-21677),
  resulting in a **33%** gain.


- There are some regression on write and search REST operation, some are related to GC problem after JSF benchmarks, [investigations in process](https://jira.nuxeo.com/browse/NXBT-1731).
"

"Nuxeo LTS 2016": "**Import**


- The nuxeo-importer is run on a single node so the synchronous part do not benefit of having multiple Nuxeo node.
  The limitation is mostly `Nuxeo CPU` at the beginning (especially for SQL backend) then `Nuxeo IO on S3`, then `SQL Backend IO`
  and `Backend CPU`.


- The asynchronous part [has been optimized](/misc/#16w11%20NXP-17934%2fNXP-17862%20audit%20and%20fulltext%20updater) since 7.10 LTS.


**Create**


- Create and Update tests scales with the number of nodes, and it is the limitation is on `Nuxeo CPU`, MongoDB is much faster than in 7.10 because [a cache has been introduced](/misc/index.html#16w44%20NXP-20640%20DBS%20cache%20enabled) to reduce the CPU load related to queries.


**Read**


- This scales with the number of Nuxeo nodes. Here also the DBS cache works fine for MongoDB and can give more than 50% gain compared to the previous LTS.


**Search**


- The switch from Elasticsearch 1.x to 2.x with the default options [shows a performance regression](/misc/index.html#16w35%20NXP-19194%20Elasticsearch%202.x)


**Update**


- Same as Create but it requires less resources from the backend, Redis overhead present on 7.10 has been fixed. Another possible limitation may be on
  the load concurrency that is not high enough.



**CRUD**


- Same as Update, mssql encounter errors on deletion [NXP-19335](https://jira.nuxeo.com/browse/NXP-19335).


**Reindex**


- For SQL Backend except for PostgreSQL limited by `Nuxeo VCS` impedance mismatch (slow document loading). For MongoDB and PostgreSQL limited by `Elasticsearch CPU`,
  the reindexing requires less memory footprint on Nuxeo and is now able to handle billion of documents.


"

"Nuxeo 8.3": "**Import**


- The nuxeo-importer is run on a single node so the synchronous part do not benefit of having multiple Nuxeo node.
  The limitation is mostly `Nuxeo CPU` at the beginning (especially for SQL backend) then `Nuxeo IO on S3`, then `SQL Backend IO`
  and `Backend CPU`.


- The asynchronous part [has been optimized](http://localhost:1313/misc/#16w11%20NXP-17934%2fNXP-17862%20audit%20and%20fulltext%20updater) since 8.1.
  When using more than 2 nodes the asynchonous jobs are processed in real time.


**Create**


- Create and Update tests scales with the number of nodes, and it is the limitation is on `Nuxeo CPU` then `Backend IO` once there are two Nuxeo nodes.


**Read**


- This scales with the number of Nuxeo nodes. The limitation is on `Nuxeo CPU` and backend latency.


**Search**


- This scales with the number of Nuxeo nodes as `Nuxeo CPU` is the first limitation.


**Update**


- Same as Create but it requires less resources from the backend, Redis overhead present on 8.1 has been fixed. Another possible limitation may be on
  the load concurrency that is not high enough.



**CRUD**


- Same as Update, mssql encounter errors on deletion [NXP-19335](https://jira.nuxeo.com/browse/NXP-19335).


**Reindex**


- For SQL Backend except for PostgreSQL limited by `Nuxeo VCS` impedance mismatch (slow document loading). For MongoDB and PostgreSQL limited by `Elasticsearch CPU`.


"


"16w35 NXP-19194 Elasticsearch 2.x": "The default Elasticsearch 2.x settings generates more disk IO on indexing and searching, the `index.translog.durability` is set by request and limits ES to the available IOPS (~750/3500 IOPS -> ~1000 req/s).
Also deletion is now handled with a scroll and deletes instead of a single recursive operation."


"16w23 NXP-19754 Test import with random dublincore properties": "**The nuxeo importer has been enhanced to generate random dublincore value:**


- This impacts the import throughput around 30%. It is still not clear if the limitation comes from the generation or the load that it creates on services
"

"16w17 NXP-19389 Search optim": "**To improve the new Search simulation results some optimizations have been done:**


- The simulations are using an empty header `X-NXfetch.document` that results in fetching all sub entities of documents
  (due to [NXP-19581](https://jira.nuxeo.com/browse/NXP-19581)).
  Not fetching all sub entities improves Reads throughput by **27%** and Search by **x2**.


- Adding a UserManager cache ([NXP-19584](https://jira.nuxeo.com/browse/NXP-19584)) helps on high throughput.
  Read simulation improves its throughput by **6%**.


- Relying on client to choose the locale instead of fetching it from the user preference [NXP-19588](https://jira.nuxeo.com/browse/NXP-19588) benefits to all REST
  access, giving a **40%** boost on Read simulation.


All cumulated the Read simulation has been improved by **x1.9** and the Search by **2.7**.


"

"Nuxeo 8.1": "**Import**


- The nuxeo-importer is run on a single node so the synchronous part do not benefit of having multiple Nuxeo node.
  The limitation is mostly `Nuxeo CPU` at the beginning then `Nuxeo IO on S3` with `Backend CPU`.


- The asynchronous part scale with the number of nodes. More async activity impacts the backend and can explain
  the throughput decrease on synchronous part when adding Nuxeo nodes.
  The limitation is mostly due to [fulltext updater](https://jira.nuxeo.com/browse/NXP-17862).


**Create/Update**


- For synchronous part the limitation is on `Nuxeo CPU` then `Backend IO` once there are two Nuxeo nodes.

- Same observation as the import for the asynchronous part.


**Navigation**


- This scales with the number of Nuxeo nodes. The limitation is on `Nuxeo CPU` and backend response time.


**Update**


- First limited by `Nuxeo CPU`, scale with more nodes then `Backend IO` limitation or `Redis CPU/IO` for MongoDB.

- The async time is incorrect [due to a bug](https://jira.nuxeo.com/browse/NXP-19092) under Redis OOM.



**CRUD**


- Same as Update, mssql encounter errors on deletion [NXP-19335](https://jira.nuxeo.com/browse/NXP-19335).


**Reindex**


- For SQL Backend limited by `Nuxeo VCS` impedance mismatch (slow document loading). For MongoDB limited by `Elasticsearch CPU`.

"

"16w12 NXBT-1018 Test default pool size": "Having more than 4 threads in the default pool improves very slightly
asynchronous tasks.


Using a bigger pool means working with more sessions and concurrency, this impacts the synchronous part.


So far it is not interesting to use more than 4 threads for the default pool.
This should be tested again once audit and ft updater optimizations are merged because
they are the first bottlenecks at the moment and they may prevent to see benefits of increasing the default pool size."


"16w11 NXP-17934/NXP-17862 audit and fulltext updater": "This benchmark suite contains 2 major optimizations:


- [NXP-17862](https://jira.nuxeo.com/browse/NXP-17862) Fulltext updater

- [NXP-17934](https://jira.nuxeo.com/browse/NXP-17934) Audit optimization refactoring


Theses optimizaton reduce asynchronous processing duration from **7x** to **11x**.

The gain comes mostly from the ft updater refactoring and 30% from audit refactoring.

The total benchmark duration is shorter from ~**75** min to ~**40** min.
"

"16w08 NXP-14923 Redis vs DB invalidation": "This suite test the default database cluster invalidation against the Redis
implementation [NXP-14923](https://jira.nuxeo.com/browse/NXP-14923).

On heavy concurrent write operation the gain can be around **2x**.
"
